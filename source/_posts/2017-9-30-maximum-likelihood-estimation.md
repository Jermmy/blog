---
title: 最大似然估计
date: 2017-9-30 13:54:29
tags: [机器学习, 概率统计]
categories: [机器学习]
mathjax: true
---

在讨论最大似然估计之前，我们先来解决这样一个问题：有一枚不规则的硬币，要计算出它正面朝上的概率。为此，我们做了 10 次实验，得到这样的结果：[1, 0, 1, 0, 0, 0, 0, 0, 0, 1]（1 代表正面朝上，0 代表反面朝上）。现在，要根据实验得到的结果来估计正面朝上的概率，即模型的参数 $p$（$0 \le p \le 1$）。

当然，对于投硬币这种问题，由于模型很简单，我们可以用大量实验来近似最终结果，不过，如果事件模型复杂一些，做大量的实验就显得不太现实。这个时候，用最大似然估计的思想，则可以通过较少的实验得出一个相对好的结果。本文就从这个简单的例子出发，对最大似然估计做一次简单的描述。

<!--more-->

### 基本思想

似然（likelihood），就是可能性的意思。所谓最大似然估计，顾名思义，就是根据最大的可能性对参数进行估计。那么什么是最大的可能性呢？对于上面那个投硬币的例子，扔 10 次硬币最可能出现的结果会是什么？最大似然估计认为，最可能出现的结果就是：[1, 0, 1, 0, 0, 0, 0, 0, 0, 1]。有人可能会纳闷，这不就是我们实验的结果吗？不错，最大似然估计有点类似于人类「先入为主」的思维。投 10 次硬币可能出现的情况有那么多，为什么偏偏我们的实验结果就是这样的呢？这是否意味着，这个结果出现的概率是最大的？

再举个例子（该例子改编自[文末链接](http://blog.csdn.net/zouxy09/article/details/8537620)）：两位猎人 A 和 B 一起外出打猎，一只野兔从两人面前窜过，两人同时开枪，结果 A 猎人射杀了野兔。如果要推测谁的枪法准，你是不是会「先入为主」地认为 A 猎人的枪法好？因为射杀兔子的可能情况有那么多种（可能是 B 射杀，也可能是 A、B 同时射杀），但偏偏发生的却是 A 射杀了兔子，那我们当然会倾向于认为 A 的枪法好一些。这种「先入为主」的思想，其实就是最大似然法的思想。简单地说，就是按照最可能的情况来评估事件。当然，这种思想多少存在误判的情况（比如，A 这次能射杀兔子纯属偶然），但随着实验次数增多，结果也会更加准确（如果两人多次狩猎，B 偶尔得手，但 A 频频得手，那 A 枪法好的可能性就更大了）。

回到硬币那个例子，同样的道理，我们认为，出现结果 [1, 0, 1, 0, 0, 0, 0, 0, 0, 1] 的可能性比其他结果要大。

### 最大似然估计的求解方法

我们先把实验的结果用数学式子表达出来：$f(x_1, x_2, \cdots , x_{10}; p)=p(1-p)p\cdots p=p^3(1-p)^7$。

现在要用最大似然估计的思想求出这里的 $p$。前面说过了，$f(x_1, x_2, \cdots , x_{10}; p)$ 出现的可能性是最大的，也就是说，$p^3(1-p)^7$ 的值要满足最大。这样一来，问题就简单多了，只要根据函数 $h(p)=p^3(1-p)^7$ 的单调性，找出使得 $h(p)$ 的值最大的 $p$ 即可。为了计算的方便，我们往往会引入对数，即 $\ln {h(p)}=\ln{p^3(1-p)^7}$，这个函数单调性和 $h(p)$ 是一致的，因此只需要求出 $\ln{h(p)}$ 的最大值即可。最大值一般来说出现在导数为 0 的时候，因此，令 $\frac{d \ln{h(p)}}{dp}=\frac{3}{p}-\frac{7}{1-p}=0$，解得 $p=\frac{3}{10}$。

换句话说，当 $p=\frac{3}{10}$ 时，$f(x_1, x_2, \cdots , x_{10}; p)$ 出现的可能性最大。因此，我们估计出来的模型参数就是 $p=\frac{3}{10}$。这个结果也符合我们的预期（10 次实验中有 3 次正面朝上）。事实上，投硬币这个简单的模型并没法完全体现出最大似然估计的威力，而且，可以证明，在这个例子中，用最大似然估计得出来的结果永远都是 $\frac{x}{n}$ （其中，n 是实验次数，x 是正面朝上的次数）。不过，在其他一些更复杂的模型中，用最大似然法来估计参数，往往是最方便有效的。

下面，我们总结一下最大似然估计的一般步骤（改自[文末链接](http://blog.csdn.net/zouxy09/article/details/8537620)）：

1. 写出似然函数；（即上文中的 $f(x_1, x_2, \cdots , x_{10}; p)$）
2. 对似然函数取对数；（因为似然函数往往是众多概率相乘的形式，对数可以方便运算）
3. 求导数，令导数为 0，得到似然方程；
4. 解方程，得到参数。

### 总结

最大似然法是在已知实验结果的基础上，估计模型参数的方法。它的基本思想是，假设实验结果出现的可能性最大，并依此反推出参数。

表述成数学语言如下：

假设我们观察到一些实验结果：$x_1, x_2, \dots, x_n$，要估计出模型参数 $\theta_1, \theta_2, \dots, \theta_m$。根据最大似然法，要让似然函数 $f(x_1, x_2, \dots, x_n; \theta_1, \theta_2, \dots, \theta_m)$ 满足：
$$
f(x_1, x_2, \dots, x_n; \hat \theta_1, \hat \theta_2, \dots, \hat \theta_m)\ge f(x_1, x_2, \dots, x_n; \theta_1, \theta_2, \dots, \theta_m)
$$
这里的 $\hat \theta_1, \hat \theta_2, \dots, \hat \theta_m$ 就是使得实验结果出现的可能性最大的参数，也是最大似然法估计出来的参数。

### 参考

+ [从最大似然到EM算法浅解](http://blog.csdn.net/zouxy09/article/details/8537620)
+ [概率与统计](https://book.douban.com/subject/1262481/)

