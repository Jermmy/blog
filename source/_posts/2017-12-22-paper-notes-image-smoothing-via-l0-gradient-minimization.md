---
title: 论文笔记：Image Smoothing via L0 Gradient Minimization
date: 2017-12-22 10:05:17
tags: [图像处理, NPR, 论文]
categories: 图像处理
mathjax: true
---

今天要分享的这篇论文是我个人最喜欢的论文之一，它的思想简单、巧妙，而且效果还相当不错。这篇论文借助数学上的 $L_0$ 范数工具对图像进行平滑，同时保留重要的边缘特征，可以实现类似水彩画的效果（见下图）。

另外这篇论文的作者[徐立](http://www.lxu.me/)也是一个相当高产的研究员。

<center>

<img src="/images/2017-12-22/l0-smoothing.png" width="600px">

</center>

<!--more-->

### 论文的目的

所谓图像平滑，就是突出图像中的低频成分，抑制高频成分，减小突变的梯度。大部分情况下，这么做的目的是为了去除图像中的噪声，因为噪声一般就是一些孤立的像素点，是像素变化比较大的区域。在传统的图像处理中，大部分操作都是用一些具有平滑性质的卷积核对图像进行模糊处理，最常用的如：[高斯模糊](http://www.ruanyifeng.com/blog/2012/11/gaussian_blur.html)、均值滤波等等。这些方法都有一个缺陷，就是在模糊噪声的同时，也模糊了边缘。当然之后也有一些改进的方法，如：[双边滤波](https://jermmy.github.io/2017/01/07/2017-1-7-Bilateral-Filter/)等，这些方法都在边缘保持上进行了很多改进，但多少还是会损失边缘的信息。本文的方法完全不同于以往的这些算法，它从图像梯度的角度出发，在平滑掉大部分细小的噪声的同时，又能最大限度的保持重要的边缘信息。

### 论文主要思想

#### 一维图像信号

在正式讲思想之前，我们先回忆一下图像平滑的目标是什么。

<center>

<img src="/images/2017-12-22/gradient.png" width="600px">

</center>

为了简单起见，我们先从一维出发，把图像当作一维的信号。那么，图像平滑就是要把那些比较小的类似「褶皱」的地方抹平，而把那些大的「褶皱」，或者更准确地说，变化很大的梯度（边缘）保留下来。上面这幅图展示的是不同算法的平滑效果。可以发现，之前的算法在平滑掉那些坑坑洼洼的「褶皱」的同时，也把可能把属于真正边缘的大的梯度给模糊了（细节放大图如下）

<center>

<img src="/images/2017-12-22/gradient-detail.png" >

</center>

为了避免这种问题，论文提出一种基于 $L_0$ 范数的能量最小化方法。

所谓 $L_0$ 范数，指的就是向量中非 0 元素的个数。论文中借用这个概念，提出一个图像梯度**数量**的计算公式：
$$
c(f)=\#\{p\ \big |\ |f_p-f_{p+1}|\neq 0 \}
$$
公式中，$f$ 表示我们平滑后的图像，$\#$ 表示集合中元素 $p$ 的个数，而 $p$ 则表示像素位置，因此 $f_p$ 其实就代表图像 $f$ 在 $p$ 这个位置的像素值。

因此这个公式其实就是在计算：满足 $|f_p-f_{p+1}| \neq 0$ 的像素数量，这个不等式正好就是 $L_0$ 范数。它的现实意义就是计算图片信号中**梯度的数量**。

有了这个公式后，论文抛出它最核心的目标函数：
$$
\underset{f} {\operatorname {min}} \sum_{p}(f_p-g_p)^2 \ \ \ \   \operatorname{s.t.} \ c(f)=k
$$
公式中的 $g$ 表示原图像，$f$ 表示平滑后的图像，$c(f)$ 就是上面提到的计算梯度数量的公式，它表示 $f$ 中的梯度数量应该为 $k$ 个。

这个公式表示的是图像 $f$ 中每个像素 $f_p$ 和原图 $g$ 中每个像素 $g_p$ 之间的平方差之和。

最小化这个目标函数，其实就是要最小化 $f$ 和 $g$ 之间的像素差。如果没有 $c(f)$ 这个限制，那么最终的优化结果就是 $f=g$。但加上 $c(f)$ 限制后，这个目标函数在尽可能减少两个信号之间的能量差的同时，又要让 $f$ 中的梯度数量满足 $k$ 个。换句话说，它要尽可能让 $f$ 和 $g$ 相似，同时又抹平 $f$ 中的梯度。因此，最后的优化结果只能是保留住 $f$ 中那些梯度比较大的边缘，而平滑掉那些梯度比较小的「褶皱」。

$c(f)$ 这个限制最大的作用就是防止 $f$ 出现对边缘的模糊。如果仔细观察上面那张边缘模糊的细节图，你就会发现，造成模糊的原因是我们把原来很「抖」的梯度变「缓」了，而缓的梯度其实是由很多小梯度组成的。$c(f)$ 的限制正是为了减少这种梯度的数量。因此，为了满足 $c(f)$，目标函数会让 $f$ 中的梯度倾向于更「抖」。

在**最小化能量差**和**减少梯度数量**这两个约束的共同博弈下，最终得到了下面的这种很平滑、同时边缘很尖锐的结果：

<center>

<img src="/images/2017-12-22/gradient-detail2.png" width="200px" >

</center>

这种相互制约的想法实在是简单而又精彩！

不过，实际应用中存在一个问题，就是 $k$ 的变化范围很大，是很难选择的。为了控制 $k$ 的选择范围，论文把 $c(f)=k$ 这个约束也加入到目标函数中：
$$
\underset{f}{\operatorname{min}} \{ \sum_p{(f_p-g_p)^2+\lambda c(f)} \}
$$
现在 $\lambda$ 代替 $k$ 作为可以调节的参数。$\lambda$ 越大，目标函数对 $c(f)$ 的抑制就越大，梯度数量就越少（即边缘越少），反之，梯度数量越大。

#### 二维图像信号

一维信号的约束可以很容易引申到二维信号：
$$
C(S)=\#\{p\ \big | \ |\partial_x S_p|+|\partial_y S_p| \neq 0 \}
$$
$S$ 类似上面提到的 $f$，在这里它表示处理后的二维图像，$\partial_x S_p$ 和 $\partial_y S_p$ 分别代表在 $x$ 方向和 $y$ 方向计算 $L_0$ 范数。

然后，我们可以用同样的方法得到目标函数：
$$
\underset{S}{\operatorname{min}} \{ \sum_p{(S_p-I_p)^2+\lambda C(S)} \}
$$
公式中 $I$ 表示原图，其他的类比一维信号的公式。

###优化方法

希望有生之年看懂补上。。。

### 实验结果

<center>

<img src="/images/2017-12-22/result1.png" >

</center>

上图（e）是论文的方法和其他图像平滑方法的对比，可以看出，这种基于 $L_0$ 平滑的方法不仅平滑的效果好，而且几乎是原封不动地保留了色块之间的边缘信息。而其他方法在色块（尤其是红色）上的平滑力度不如 $L_0$ 平滑，且边缘也模糊了不少。

另外，论文的平滑方法在边缘提取上效果也相当的好，下图中，左边（e）是直接对原图用 Canny 提取边缘的结果，右边是先用 $L_0$ smoothing 进行平滑，再提取边缘的结果，可以看到，平滑后提取的边缘中抹去了很多不重要的细节，而主要的边缘信息都被提取出来。

<center>

<img src="/images/2017-12-22/edge-detection.png" width="400px" >

</center>

除此之外，另一个很重要的用途是图像失量化。图像失量化要求图像中的色块数量尽可能少，而这一点正中 $L_0$ smoothing 下怀。下图中的输入图像具有很多噪声细节，而这些细节用一般的平滑方向是很难根除的，但 $L_0$ smoothing 由于限制了梯度数量，因此可以产生很「光滑」的色块区域，非常利于失量化操作。

<center>

<img src="/images/2017-12-22/vectorize.png" >

</center>



### 参考

+ [Image Smoothing via L0 Gradient Minimization](http://www.cse.cuhk.edu.hk/~leojia/papers/L0smooth_Siggraph_Asia2011.pdf)
+ [L0范数图像平滑](http://blog.csdn.net/bluecol/article/details/48750561)
+ [机器学习中的范数规则化之（一）L0、L1与L2范数](http://blog.csdn.net/zouxy09/article/details/24971995)